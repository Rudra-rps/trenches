# LLM Configuration
api_key: ""  # Set via GROQ_API_KEY environment variable
base_url: "https://api.groq.com/openai/v1"
default_model: "llama-3.1-8b-instant"
default_temperature: 0.7
default_max_tokens: 100
request_timeout: 30
retry_attempts: 3
available_models:
  - "llama-3.1-8b-instant"
  - "llama3-8b-8192"
  - "llama3-70b-8192"
  - "mixtral-8x7b-32768"
  - "gemma-7b-it"
default_headers:
  Content-Type: "application/json"

